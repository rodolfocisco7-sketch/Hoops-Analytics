name: NBA Data Scraper

on:
  schedule:
    - cron: '0 19 * * *'   # 2:00 PM Panam√°
    - cron: '0 5 * * *'    # 12:00 PM Panam√°
  workflow_dispatch:

# üü¢ SOLUCI√ìN 1: Damos permiso expl√≠cito para escribir en el repo
permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        # üü¢ SOLUCI√ìN 2: Aseguramos que bajamos la rama 'main', no un commit suelto
        ref: main 

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run scraper
      run: |
        python scraper_automatico.py
      continue-on-error: false

    - name: Commit and Push
      run: |
        # Configurar identidad
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'

        # üü¢ SOLUCI√ìN 3: Sincronizamos ANTES de a√±adir nada para evitar conflictos
        # Esto descarga lo √∫ltimo de GitHub y lo fusiona suavemente
        git pull origin main --no-rebase || echo "Nada que pullear o conflicto menor"

        # A√±adimos los cambios generados por el scraper
        git add data/

        # Verificamos si hay algo real que subir
        if git diff --staged --quiet; then
          echo "‚ÑπÔ∏è No hay cambios en la data. Terminando."
        else
          echo "‚úÖ Cambios detectados. Creando commit..."
          git commit -m "ü§ñ Auto-update NBA data - $(date -u +'%Y-%m-%d %H:%M UTC')"
          
          # Push directo. Si falla aqu√≠, queremos ver el error real, no ocultarlo en un loop.
          git push origin main
        fi

    - name: Verificar estado final
      if: always()
      run: |
        echo "üìä √öltimo estado:"
        ls -lh data/