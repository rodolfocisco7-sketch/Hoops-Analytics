# .github/workflows/scraper.yml
name: NBA Data Scraper

on:
  schedule:
    # Corre 3 veces al d칤a (UTC - ajusta seg칰n tu zona)
    # 11:00 UTC = 6:00 AM Panam치 (UTC-5)
    - cron: '0 11 * * *'  
    # 19:00 UTC = 2:00 PM Panam치
    - cron: '0 19 * * *'  
    # 03:00 UTC = 10:00 PM Panam치 (d칤a anterior)
    - cron: '0 3 * * *'   
  
  workflow_dispatch:  # Permite ejecuci칩n manual desde GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run scraper
      run: |
        python scraper_automatico.py
      continue-on-error: true  # No falla si hay errores parciales
    
    - name: Commit and push if changed
      run: |
        git config --global user.name 'GitHub Actions Bot'
        git config --global user.email 'actions@github.com'
        git add data/
        # Solo procedemos si hay cambios reales en la carpeta data
        if [ -n "$(git status --porcelain data/)" ]; then
          git commit -m "游뱄 Auto-update data $(date +'%Y-%m-%d %H:%M UTC')"
          # El truco: Usar -X theirs para que en caso de conflicto, 
          # siempre gane la versi칩n de los datos nuevos del bot.
          git pull --rebase -X theirs origin main
          git push origin main
        else
          echo "No hay cambios en los datos, saltando push."
        fi